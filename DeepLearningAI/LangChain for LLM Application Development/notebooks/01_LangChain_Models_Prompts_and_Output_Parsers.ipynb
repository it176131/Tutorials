{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98028637-e9c7-4248-9191-0f8fe64d2185",
   "metadata": {},
   "source": [
    "\"Models\" refer to (Large) Language Models.\n",
    "\"Prompts\" refer to the style of creating inputs to pass to the models.\n",
    "\"Parsers\" refer to taking the output of the models and parsing it into a more structured format that can be used downstream.\n",
    "\n",
    "When you build an application using an LLM, the model will be reusable.\n",
    "We repeatedly prompt a model and parse the output.\n",
    "`LangChain` gives an easy set of abstractions to do this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59b3f23-26f9-4891-b605-136f526af666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec529c2-7c41-40fa-a90c-1ae544610ce1",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0676a9-d3a7-47a1-92e0-96a04b73d62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.2.3\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: C:\\Users\\A2644752\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\n",
      "Requires: anyio, distro, httpx, pydantic, tqdm, typing-extensions\n",
      "Required-by: instructor\n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ccdc26-939c-44a8-8d06-21a5f999e34b",
   "metadata": {},
   "source": [
    "OpenAI version 1.0.0 introduced an API change.\n",
    "See [here](https://github.com/openai/openai-python/discussions/742) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3af4719-a58e-461a-9d8d-a9fd03440280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai.lib.azure import AzureOpenAI\n",
    "from openai.types.chat.chat_completion import ChatCompletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6653cadd-10de-43ed-bfed-8ccbff72f78b",
   "metadata": {},
   "source": [
    "Available API versions can be found [here](https://github.com/Azure/azure-rest-api-specs/tree/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference).\n",
    "- [Preview](https://github.com/Azure/azure-rest-api-specs/tree/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/preview)\n",
    "- [Stable](https://github.com/Azure/azure-rest-api-specs/tree/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb894051-9c2a-49c8-9fb0-129fa3dac102",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_version = \"2023-12-01-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d244002-20c5-4dd9-81c7-010332ba8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = AzureOpenAI(api_version=api_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9348a8-8ed9-480d-9493-94fd1771d9b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "My Azure account requires the deployment name rather than the model name.\n",
    "Use `model: str = \"gpt-35-turbo-16k\"` instead of `model: str = \"gpt-3.5-turbo\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020b02f2-5848-4e4e-b7a3-c9415c1c888c",
   "metadata": {},
   "source": [
    "`openai.ChatCompletion.create` was replaced with:\n",
    "- `AzureOpenAI(...).chat.completions.create` if using AzureOpenAI\n",
    "- `OpenAI(...).chat.completions.create` if using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92f2526a-5198-415f-aa88-abb2d007ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt: str, model: str = \"gpt-35-turbo-16k\") -> str:\n",
    "    \"\"\"Given a prompt and model, return the content of the response.\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response: ChatCompletion = openai.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1908119-8435-4ffc-b673-083e978209b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309663d2-9801-4ae8-8f2f-8b31dc73f5e0",
   "metadata": {},
   "source": [
    "To motivate the LangChain abstractions for model prompts and parsers, suppose you get an email in a language other than english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7a9a431-b6c5-45e2-a556-cd0a4c5b32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"\"\"\n",
    "Arr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6262d4-7e33-41d8-a60c-258a81d95a56",
   "metadata": {},
   "source": [
    "We can translate the message by asking the LLM to rewrite it in a given style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d929e79c-0bcf-49c6-b9a4-051bd32d61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af6edda9-b58d-4909-aaa9-d33bbf9d133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks\n",
    "into a style that is {style}.\n",
    "text: ```{email}```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88959506-44e8-44a1-8aba-0c3456581e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks\n",
      "into a style that is American English in a calm and respectful tone\n",
      ".\n",
      "text: ```\n",
      "Arr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a827fa01-cd1e-4bae-be8a-852a8d904deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "438dcc0c-9de9-41bc-a4a5-73622b95b543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm really frustrated that my blender lid flew off and made a mess of my kitchen walls with smoothie! And to make things even worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help at this moment, my friend.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e5b787-929b-4b04-b7a2-d5a13a4fd751",
   "metadata": {},
   "source": [
    "We can do this in a more convenient way with `LangChain`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e50d286-2e04-4d33-8ee3-0add3f5fe7b0",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959ffc5-7c3b-4a84-bed0-3ef28ba729c2",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1dc4500-30c0-42a2-af11-6aa6fe732414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models.azure_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1720017-1b60-4bac-9319-e0d485915c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000211053F98D0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000021105419C90>, model_name='gpt-35-turbo-16k', temperature=0.0, openai_api_key='aac22590f900414faaf3637e450a96ae', openai_proxy='', azure_endpoint='https://a3d0dvexroai01t.openai.azure.com/', openai_api_version='2023-12-01-preview', openai_api_type='azure')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = AzureChatOpenAI(model=\"gpt-35-turbo-16k\", temperature=0, api_version=api_version)\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5120784e-5d92-46e6-a92d-a6598c7c3224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.chat_models.azure_openai.AzureChatOpenAI"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b98e6-c824-45c1-8114-22cdcd598248",
   "metadata": {},
   "source": [
    "`AzureChatOpenAI` is a `LangChain` object that offers additional attributes and methods over the `AzureOpenAI` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a062b6c-0c6c-4bfd-a5f6-bf59ad74a642",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465d9b1-abe2-46c7-b264-2ea93c887bc0",
   "metadata": {},
   "source": [
    "We use the same prompt, but not as an `f-string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ad21c59-bd23-46be-91bf-680ed0338e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks\n",
    "into a style that is {style}.\n",
    "text: ```{email}```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdcd55ef-ff68-4d47-b5ff-c7f00fe65828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f1ef2-8312-4fdd-b2fe-20dd7b6f6f6a",
   "metadata": {},
   "source": [
    "The `ChatPromptTemplate` has `classmethod`s for constructing a prompt given a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ea726e9-516b-4a7f-a1cd-88f89f1c8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5c4c0d5-9a0d-4f0c-980b-39fa601c2df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['email', 'style'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['email', 'style'], template='Translate the text that is delimited by triple backticks\\ninto a style that is {style}.\\ntext: ```{email}```'))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6305928-1b22-4874-9002-1dc1d23bd02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.chat.ChatPromptTemplate"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cf0afe5-1981-4ee1-9f93-adaf714c6655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['email', 'style'], template='Translate the text that is delimited by triple backticks\\ninto a style that is {style}.\\ntext: ```{email}```')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6ca258-0def-4aba-a551-98eb2bd1a7e6",
   "metadata": {},
   "source": [
    "We can see that the `prompt_template` has identified two input variables, `email` and `style`.\n",
    "These were surrounded by braces (`{}`) in the template string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b854ba0-5f33-4791-ad3e-c2e5803fb5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['email', 'style']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d14783-bc2b-42b3-8f78-1868d43edecc",
   "metadata": {},
   "source": [
    "We can set values to the input variables with `format_messages`.\n",
    "If we forget a required `input_variable`, a `KeyError` will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d75410e2-ecac-4719-be0d-f141d30fb725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'style'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:611\u001b[0m, in \u001b[0;36mChatPromptTemplate.format_messages\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    604\u001b[0m     message_template, (BaseMessagePromptTemplate, BaseChatPromptTemplate)\n\u001b[0;32m    605\u001b[0m ):\n\u001b[0;32m    606\u001b[0m     rel_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    607\u001b[0m         k: v\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    609\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m message_template\u001b[38;5;241m.\u001b[39minput_variables\n\u001b[0;32m    610\u001b[0m     }\n\u001b[1;32m--> 611\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43mmessage_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrel_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    612\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(message)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:220\u001b[0m, in \u001b[0;36mBaseStringMessagePromptTemplate.format_messages\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_messages\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseMessage]:\n\u001b[0;32m    212\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format messages from kwargs.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \n\u001b[0;32m    214\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m        List of BaseMessages.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain_core\\prompts\\chat.py:276\u001b[0m, in \u001b[0;36mHumanMessagePromptTemplate.format\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    268\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format the prompt template.\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m        Formatted message.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HumanMessage(content\u001b[38;5;241m=\u001b[39mtext, additional_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_kwargs)\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain_core\\prompts\\prompt.py:132\u001b[0m, in \u001b[0;36mPromptTemplate.format\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format the prompt with the inputs.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m        prompt.format(variable1=\"foo\")\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_partial_and_user_variables(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULT_FORMATTER_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\string.py:190\u001b[0m, in \u001b[0;36mFormatter.format\u001b[1;34m(self, format_string, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain_core\\utils\\formatting.py:29\u001b[0m, in \u001b[0;36mStrictFormatter.vformat\u001b[1;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo arguments should be provided, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meverything should be passed as keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m     )\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\string.py:194\u001b[0m, in \u001b[0;36mFormatter.vformat\u001b[1;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, args, kwargs):\n\u001b[0;32m    193\u001b[0m     used_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m--> 194\u001b[0m     result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mused_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_unused_args(used_args, args, kwargs)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\string.py:234\u001b[0m, in \u001b[0;36mFormatter._vformat\u001b[1;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[0m\n\u001b[0;32m    230\u001b[0m     auto_arg_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# given the field_name, find the object it references\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m#  and the argument it came from\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m obj, arg_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m used_args\u001b[38;5;241m.\u001b[39madd(arg_used)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# do any conversion on the resulting object\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\string.py:299\u001b[0m, in \u001b[0;36mFormatter.get_field\u001b[1;34m(self, field_name, args, kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_field\u001b[39m(\u001b[38;5;28mself\u001b[39m, field_name, args, kwargs):\n\u001b[0;32m    297\u001b[0m     first, rest \u001b[38;5;241m=\u001b[39m _string\u001b[38;5;241m.\u001b[39mformatter_field_name_split(field_name)\n\u001b[1;32m--> 299\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;66;03m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m#  getattr or getitem as needed\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m is_attr, i \u001b[38;5;129;01min\u001b[39;00m rest:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\string.py:256\u001b[0m, in \u001b[0;36mFormatter.get_value\u001b[1;34m(self, key, args, kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args[key]\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'style'"
     ]
    }
   ],
   "source": [
    "prompt_template.format_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5c029de-6bf9-4477-9fc0-d0dbf6b52b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = prompt_template.format_messages(style=style, email=email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1496431d-7c4f-47b2-88ed-80aee020429e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Translate the text that is delimited by triple backticks\\ninto a style that is American English in a calm and respectful tone\\n.\\ntext: ```\\nArr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\")]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfeeb5ed-5802-4a54-8dec-b12764b71bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a246708f-d152-447b-ad1c-84e93a0b0043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.human.HumanMessage"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "429136c0-9774-46fb-8890-24c6101b70d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm really frustrated that my blender lid flew off and made a mess of my kitchen walls with smoothie! And to make things even worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help at this moment, my friend.\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(messages=messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb645c2-eaf0-4507-bedf-5ec8af6cf601",
   "metadata": {},
   "source": [
    "We can reverse-translate our response using a similar technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2badc736-a717-4ce7-8c8f-e8979e789850",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover ]\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tought luck! See ya!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89b79106-7fae-4847-80a5-fa0f79ffe647",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_style = \"\"\"\n",
    "A polite tone \\\n",
    "that speaks in English Pirate\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbaada62-9a15-4c9a-98ed-8f7ea7df5cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_messages = prompt_template.format_messages(style=reply_style, email=reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99b2d7bc-ad0c-4ad9-990d-d6349e263f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks\n",
      "into a style that is \n",
      "A polite tone that speaks in English Pirate.\n",
      "text: ```Hey there customer, the warranty does not cover ]\n",
      "cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tought luck! See ya!```\n"
     ]
    }
   ],
   "source": [
    "print(reply_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b26d038-4015-444f-b0f5-f3d1b8a7471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arr, me hearty customer, the warranty be not coverin' yer cleaning expenses fer yer galley 'cause 'tis yer fault ye misused yer blender by forgettin' to put the lid on afore startin' the blender. Tis a tough luck, matey! Fare thee well!\n"
     ]
    }
   ],
   "source": [
    "response = chat(reply_messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16304b9-62cf-4503-bb9a-71a8d99eef61",
   "metadata": {},
   "source": [
    "Prompt templates provide us with a greater level of abstraction vs `f-strings` as the prompts become longer and more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a84e9e3-56fd-416d-a20a-39724a1aa14d",
   "metadata": {},
   "source": [
    "## Output Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26792363-eab5-4ab5-922e-5ed26ef1c128",
   "metadata": {},
   "source": [
    "We can extract information with the LLM and format it as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e418ad5-826f-4f83-be75-fd7863cb2919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"gift\": False,\n",
    "    \"delivery_days\": 5,\n",
    "    \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ae96556-da0c-47a3-b784-cc72bd88dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"\n",
    "This leaf blower is pretty amazing. It has four settings \\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversay present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "211ecc9d-9c17-464f-b583-d03f049925f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template = \"\"\"\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delviery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price, \\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ace0a43-c16f-47fc-86a3-e71a06c7d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c6a65bc-ad29-4975-bd76-7060c3c69c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(template=review_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "712b6549-9d95-4750-a604-224f50e12e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00267523-ec0d-47e7-8398-3c54dc6e5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = prompt_template.format_messages(text=review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55704a27-d69c-4014-85fa-6b9eb4ffa1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\\n  \"gift\": false,\\n  \"delivery_days\": 2,\\n  \"price_value\": [\"It\\'s slightly more expensive than the other leaf blowers out there, but I think it\\'s worth it for the extra features.\"]\\n}')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = AzureChatOpenAI(model=\"gpt-35-turbo-16k\", temperature=0, api_version=api_version)\n",
    "response = chat(messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02cc409-8f57-4adf-8284-9c429dc3e7a2",
   "metadata": {},
   "source": [
    "By default the LLM will return the response content as a string.\n",
    "We can convert it to another Python object using an `OutputParser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6c5f9a8-d822-44fb-91a6-2832b0a811c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This raises an error because the response.content is a string.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgift\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# This raises an error because the response.content is a string.\n",
    "response.content.get(\"gift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3104a2-f577-40e6-990b-829ae038b090",
   "metadata": {},
   "source": [
    "## Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16c212ff-393b-4d33-8870-7e6a70abb352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036422aa-5434-4b4e-b99f-85ed9c861414",
   "metadata": {},
   "source": [
    "We define what we want the response to look like using the `ResponseSchema`.\n",
    "This is similar to a `pydantic.Field` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4cfebd53-6084-48ec-ac16-824de469553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(\n",
    "    name=\"gift\",\n",
    "    description=\"Was the item purchased as a gift for someone else? \\\n",
    "    Answer True if yes, False if not or unknown.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc25d2f0-9752-4a5a-a678-1305ed5e590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_days_schema = ResponseSchema(\n",
    "    name=\"delivery_days\",\n",
    "    description=\"How many days did it take for the product \\\n",
    "    to arrive? If this information is not found, output -1.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4583a717-2ac7-4991-b35b-9d2189ba913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_value_schema = ResponseSchema(\n",
    "    name=\"price_value\",\n",
    "    description=\"Extract any sentences about the value or price, \\\n",
    "    and output them as a comma separated Python list.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8db7540-7e8d-4430-b8a9-e0929abefafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "    gift_schema,\n",
    "    delivery_days_schema,\n",
    "    price_value_schema,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a1ef8c-7cf6-4a11-bcfa-efd596408102",
   "metadata": {},
   "source": [
    "We create a `StructuredOutputParser` using the `response_schemas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a95cfb48-e76d-472c-a580-6c674100bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas=response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5f5161a-f1b2-4258-a846-38e6d833128d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.output_parsers.structured.StructuredOutputParser"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b9d70d-e357-4f70-ac5f-1a483cef0157",
   "metadata": {},
   "source": [
    "The response schema is formatted with instructions for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a537f47-8579-45a4-b99f-95cf2ab15e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25d3c0ff-3441-4f17-8f98-5a7a49c41263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased as a gift for someone else?     Answer True if yes, False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days did it take for the product     to arrive? If this information is not found, output -1.\n",
      "\t\"price_value\": string  // Extract any sentences about the value or price,     and output them as a comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9788b685-4e61-4461-bbf2-c053f1c3bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9e858f4-c623-4a38-a3d9-ee1071a98caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "acd2e61f-6ec1-4340-a524-85128ba33a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = prompt.format_messages(text=review, format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb898e18-dacd-4929-8e26-449c6eedddaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "text: \n",
      "This leaf blower is pretty amazing. It has four settings candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversay present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased as a gift for someone else?     Answer True if yes, False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days did it take for the product     to arrive? If this information is not found, output -1.\n",
      "\t\"price_value\": string  // Extract any sentences about the value or price,     and output them as a comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de1475df-146f-49f2-8e0f-17019f7b9db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b99da753-c188-4210-b7cd-ca371a63be86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": false,\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b74121-446a-4476-a18c-d1875556cc4d",
   "metadata": {},
   "source": [
    "The LLM does a much better job at formatting the response, though it's still a string.\n",
    "The `output_parser` can `parse` the `response.content` to the type referenced by the backticks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c5beae6-abbd-4752-a086-536af2514ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(text=response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de2dbd41-40a3-4b96-b3e8-b28cb8aae435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False,\n",
       " 'delivery_days': '2',\n",
       " 'price_value': \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99ad7fa3-78a0-47d1-8d9f-650a420eaccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bdc49e35-e4f8-47fc-8801-484cbc7be433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get(\"delivery_days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885efb5-0513-4e5f-9bf8-17770e2c159c",
   "metadata": {},
   "source": [
    "# Example: Glassdoor\n",
    "\n",
    "Extract information about the the job.\n",
    "These can include:\n",
    "- Job title\n",
    "- Job requirements\n",
    "- Salary\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018604d7-ee87-45c8-ac9a-c9602609c78a",
   "metadata": {},
   "source": [
    "Job Posting: [EpochGeo Senior Geospatial Data Scientist](https://www.glassdoor.com/job-listing/senior-geospatial-data-scientist-epochgeo-JV_IC1154429_KO0,32_KE33,41.htm?jl=1009032709165&src=GD_JOB_AD&uido=8B6EC23126E2A08BC7C88CF7E97323BD&ao=1110586&jrtk=5-yul1-1-1hj5n71lqirpp801-a82b63c926f1e7c6---6NYlbfkN0D54-4lvN4MbGSrnJofeUamWKLLgEBO_tp8_vrY9hHPomI097Pi-K_0gT_S7OouJqmg_XOLI1XleosxlDnZhQaFqDHNuTHvSSjyRL5izvOeA3W_H0PV6ptDqSGfjTkCTKFD-wDd8Us1dGp1AZTgt0V8a8iirU-VZFNAUfPZnsAAvqIXTZC5Y3-fTYqCB8WUWOgXWn1GXD_fvOePVmxxqSKYjhaVAril0jdaZ2rLWwPJdKUQUx79FTYO7gUexzNPwHCDo9Gbqg-AM5__cdImSRuMR0EjO3b9XKciAjuOqbfzcMM0tqd8ZWkG3abWtkUy46TDqIHiHzKV1cfhhx-6mDOokV6Ju0AlgYGpt9RKetfqr1Xd9UKO0bp8UIE9JIw9fV7AgfsqJmTGQ6whHcKbtTKBMN62m0YOPrsyn_3VfnEflZL38nBTP7rlSI-Gx9TfXlNitYSkZYTF7w12q1ENWOj9t8AdYIojeL-lpHVQsdUlF0l9t6mrgstBCUNwyoBv7Vwisin6h-KN1cDMCZRvnbTu9Aqwor5rz6LfYhIAgcoGQYbh58BtM94BpdDNEOi1huaJE3ZbmpF-9Z1omv5BPPN4APm0jm2jQX-_2UyXHkds_uRZzW3I_6rm&cs=1_3269eb64&s=353&t=REC_JOBS&pos=101&cpc=983919718F9DC6F6&guid=0000018ccb73867ebc29def00db18b26&jobListingId=1009032709165&ea=1&vt=w&cb=1704220395502&ctt=1704221634537)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09973597-45a0-4a43-95a4-3d5fb6345b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "posting = \"\"\"Senior Geospatial Data Scientist\n",
    "\n",
    "EpochGeo is looking for a senior level Geospatial Data Scientist in Tampa, Florida to support one of the most innovative, exciting, and growing offices that is rooted in data rich projects in the national security space.\n",
    "\n",
    "Are you a technical analyst who loves to work with data, find patterns in it, and then turn it into actionable intelligence? Are you a data scientist who loves to draw out insights from data, and work with analysts and engineers to turn those insights into automated workflows? If so, please reach out to us at EpochGeo to chat.\n",
    "\n",
    "Location-based big data can be overwhelming, inaccessible, and noisy. EpochGeo is a data services firm specializing in supporting the full spectrum data cycle: beginning with scalable data storage and ending in producing impactful analytics. Our developers, analysts, and data scientists have a proven track record applying open-source innovative technology, data science, and actionable analytics to inform customers data driven decisions.\n",
    "\n",
    "Your background likely includes:\n",
    "\n",
    "10+ years of experience working in US DoD and IC environments, preferably with CENTCOM or other COCOM elements.\n",
    "Education in Geography, Data Science, Economics, Computer Science, etc.\n",
    "Military and/or DoD/IC experience in any of the following disciplines: data science, computer vision, target development, geospatial, or statistical analysis.\n",
    "Experience with spatial data and map based visualization tools along with data science fundamentals such as data engineering, coding in python, SQL, data structures and familiarity with Keras, Tensorflow, Neo4j, or PyTorch frameworks preferred.\n",
    "Defining critical intelligence topics, initiating comprehensive research efforts, and analyzing intelligence information to assess developments, trends, and threat implications.\n",
    "Familiarity with machine learning and statistical methods applications to solve complex problem sets and achieve successful outcomes.\n",
    "Some experience querying, creating, and integrating data flows from an Elasticsearch instance to include building dashboards and presenting information via Kibana or Plotly Dash.\n",
    "Applied GIS work and familiarity with ESRI products and/or QGIS.\n",
    "What you will be doing:\n",
    "\n",
    "Communicating with the project team, user community, and high level client leadership to understand requirements and demonstrate iterative progress.\n",
    "Exploiting multiple data and information environments for insights that can be automated at scale with developer assistance.\n",
    "Working with a multi-discipline team to build automated tipping and cueing and/or alert generation tools.\n",
    "Preparing Intelligence, data visualization products and finished intelligence and presenting them to a variety of audiences including senior leadership.\n",
    "Exploiting multiple geospatial big data environments for insights that can be automated at scale with developer assistance.\n",
    "Scripting in python to automate geospatial workflow, connecting to existing APIs to feed algorithms and/or front-end UIs.\n",
    "Conceiving and constructing working prototypes and first of their kind proof of concepts to push the art of the possible against real world problem sets.\n",
    "Working with data to enable software engineers to build upon automated tipping and cueing, alert generation tools, while developing trends to demonstrate states of readiness and forecasting future values.\n",
    "Working in a dynamic environment with ever evolving requirements.\n",
    "Bonus:\n",
    "\n",
    "Masters degree in Data Science, Geography, Statistics, Machine Learning, or related technical field\n",
    "Additional:\n",
    "\n",
    "Must hold a TS/SCI clearance and be willing to submit for a CI Poly\n",
    "Benefits Include:\n",
    "\n",
    "100% health care premiums covered, FSA, HSA\n",
    "401k: 6% match, immediate vesting\n",
    "14 holidays: All 11 Federal holidays, day after Thanksgiving, 24 DEC, 31 DEC\n",
    "PTO: 4 weeks annually\n",
    "3 week sabbatical every 3 years with the company\n",
    "Job Type: Full-time\n",
    "\n",
    "Pay: From $160,000.00 per year\n",
    "\n",
    "Benefits:\n",
    "\n",
    "401(k)\n",
    "401(k) matching\n",
    "Dental insurance\n",
    "Flexible schedule\n",
    "Flexible spending account\n",
    "Health insurance\n",
    "Health savings account\n",
    "Life insurance\n",
    "Paid time off\n",
    "Parental leave\n",
    "Professional development assistance\n",
    "Referral program\n",
    "Tuition reimbursement\n",
    "Vision insurance\n",
    "Compensation package:\n",
    "\n",
    "Bonus opportunities\n",
    "Experience level:\n",
    "\n",
    "10 years\n",
    "Schedule:\n",
    "\n",
    "8 hour shift\n",
    "Application Question(s):\n",
    "\n",
    "Please list years of experience scripting in python:\n",
    "Security clearance:\n",
    "\n",
    "Top Secret (Required)\n",
    "Ability to Commute:\n",
    "\n",
    "Tampa, FL 33621 (Required)\n",
    "Work Location: In person\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0ce9c46d-b96d-466c-952e-977bed40e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "For the following text, extract the following information:\n",
    "\n",
    "job_title: The title of the job posting.\n",
    "\n",
    "job_requirements: The minimum requirements to apply for the job.\n",
    "\n",
    "salary: The expected salary for the job.\n",
    "\n",
    "text: {posting}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b9dbf81e-e1aa-47c3-9e62-6d4139d79450",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cdcbbcad-4a04-48a2-b48f-22ea453915dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['format_instructions', 'posting'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'posting'], template='\\nFor the following text, extract the following information:\\n\\njob_title: The title of the job posting.\\n\\njob_requirements: The minimum requirements to apply for the job.\\n\\nsalary: The expected salary for the job.\\n\\ntext: {posting}\\n\\n{format_instructions}\\n'))])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "caba2321-ff83-4539-8e69-4c0dc7f1848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb6ce181-073b-4998-8e8b-466d65a1c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_schema = ResponseSchema(\n",
    "    name=\"job_title\",\n",
    "    description=\"The title of the job posting.\",\n",
    "    type=\"string\",\n",
    ")\n",
    "\n",
    "job_requirements_schema = ResponseSchema(\n",
    "    name=\"job_requirements\",\n",
    "    description=\"The minimum requirements to apply for the job.\",\n",
    "    type=\"list[string]\",\n",
    ")\n",
    "\n",
    "salary_schema = ResponseSchema(\n",
    "    name=\"salary\",\n",
    "    description=\"The expected salary for the job.\",\n",
    "    type=\"float\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "698baac0-9592-4982-81a1-9032e4d25edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "    job_title_schema,\n",
    "    job_requirements_schema,\n",
    "    salary_schema,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6923ed40-c596-441b-996c-bac45ec78d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas=response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4fbd2069-3684-461b-a3e9-d83d0e3d2622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.output_parsers.structured.StructuredOutputParser"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ccd4d16c-75c5-4d1b-98e9-00dc6004ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"job_title\": string  // The title of the job posting.\n",
      "\t\"job_requirements\": list[string]  // The minimum requirements to apply for the job.\n",
      "\t\"salary\": float  // The expected salary for the job.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85a6e8a0-64ce-4dc9-9887-e9fc3313cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7547280c-851b-45a2-b62e-02fee604204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = prompt.format_messages(posting=posting, format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "feed29ce-3a29-49f9-8695-194ca369413c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='\\nFor the following text, extract the following information:\\n\\njob_title: The title of the job posting.\\n\\njob_requirements: The minimum requirements to apply for the job.\\n\\nsalary: The expected salary for the job.\\n\\ntext: Senior Geospatial Data Scientist\\n\\nEpochGeo is looking for a senior level Geospatial Data Scientist in Tampa, Florida to support one of the most innovative, exciting, and growing offices that is rooted in data rich projects in the national security space.\\n\\nAre you a technical analyst who loves to work with data, find patterns in it, and then turn it into actionable intelligence? Are you a data scientist who loves to draw out insights from data, and work with analysts and engineers to turn those insights into automated workflows? If so, please reach out to us at EpochGeo to chat.\\n\\nLocation-based big data can be overwhelming, inaccessible, and noisy. EpochGeo is a data services firm specializing in supporting the full spectrum data cycle: beginning with scalable data storage and ending in producing impactful analytics. Our developers, analysts, and data scientists have a proven track record applying open-source innovative technology, data science, and actionable analytics to inform customers data driven decisions.\\n\\nYour background likely includes:\\n\\n10+ years of experience working in US DoD and IC environments, preferably with CENTCOM or other COCOM elements.\\nEducation in Geography, Data Science, Economics, Computer Science, etc.\\nMilitary and/or DoD/IC experience in any of the following disciplines: data science, computer vision, target development, geospatial, or statistical analysis.\\nExperience with spatial data and map based visualization tools along with data science fundamentals such as data engineering, coding in python, SQL, data structures and familiarity with Keras, Tensorflow, Neo4j, or PyTorch frameworks preferred.\\nDefining critical intelligence topics, initiating comprehensive research efforts, and analyzing intelligence information to assess developments, trends, and threat implications.\\nFamiliarity with machine learning and statistical methods applications to solve complex problem sets and achieve successful outcomes.\\nSome experience querying, creating, and integrating data flows from an Elasticsearch instance to include building dashboards and presenting information via Kibana or Plotly Dash.\\nApplied GIS work and familiarity with ESRI products and/or QGIS.\\nWhat you will be doing:\\n\\nCommunicating with the project team, user community, and high level client leadership to understand requirements and demonstrate iterative progress.\\nExploiting multiple data and information environments for insights that can be automated at scale with developer assistance.\\nWorking with a multi-discipline team to build automated tipping and cueing and/or alert generation tools.\\nPreparing Intelligence, data visualization products and finished intelligence and presenting them to a variety of audiences including senior leadership.\\nExploiting multiple geospatial big data environments for insights that can be automated at scale with developer assistance.\\nScripting in python to automate geospatial workflow, connecting to existing APIs to feed algorithms and/or front-end UIs.\\nConceiving and constructing working prototypes and first of their kind proof of concepts to push the art of the possible against real world problem sets.\\nWorking with data to enable software engineers to build upon automated tipping and cueing, alert generation tools, while developing trends to demonstrate states of readiness and forecasting future values.\\nWorking in a dynamic environment with ever evolving requirements.\\nBonus:\\n\\nMasters degree in Data Science, Geography, Statistics, Machine Learning, or related technical field\\nAdditional:\\n\\nMust hold a TS/SCI clearance and be willing to submit for a CI Poly\\nBenefits Include:\\n\\n100% health care premiums covered, FSA, HSA\\n401k: 6% match, immediate vesting\\n14 holidays: All 11 Federal holidays, day after Thanksgiving, 24 DEC, 31 DEC\\nPTO: 4 weeks annually\\n3 week sabbatical every 3 years with the company\\nJob Type: Full-time\\n\\nPay: From $160,000.00 per year\\n\\nBenefits:\\n\\n401(k)\\n401(k) matching\\nDental insurance\\nFlexible schedule\\nFlexible spending account\\nHealth insurance\\nHealth savings account\\nLife insurance\\nPaid time off\\nParental leave\\nProfessional development assistance\\nReferral program\\nTuition reimbursement\\nVision insurance\\nCompensation package:\\n\\nBonus opportunities\\nExperience level:\\n\\n10 years\\nSchedule:\\n\\n8 hour shift\\nApplication Question(s):\\n\\nPlease list years of experience scripting in python:\\nSecurity clearance:\\n\\nTop Secret (Required)\\nAbility to Commute:\\n\\nTampa, FL 33621 (Required)\\nWork Location: In person\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"job_title\": string  // The title of the job posting.\\n\\t\"job_requirements\": list[string]  // The minimum requirements to apply for the job.\\n\\t\"salary\": float  // The expected salary for the job.\\n}\\n```\\n')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5bb37c41-6c9f-4136-b153-990597a8cd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "93620d24-f24b-4139-854a-568da95b823f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"job_title\": \"Senior Geospatial Data Scientist\",\n",
      "\t\"job_requirements\": [\n",
      "\t\t\"10+ years of experience working in US DoD and IC environments, preferably with CENTCOM or other COCOM elements.\",\n",
      "\t\t\"Education in Geography, Data Science, Economics, Computer Science, etc.\",\n",
      "\t\t\"Military and/or DoD/IC experience in any of the following disciplines: data science, computer vision, target development, geospatial, or statistical analysis.\",\n",
      "\t\t\"Experience with spatial data and map based visualization tools along with data science fundamentals such as data engineering, coding in python, SQL, data structures and familiarity with Keras, Tensorflow, Neo4j, or PyTorch frameworks preferred.\",\n",
      "\t\t\"Defining critical intelligence topics, initiating comprehensive research efforts, and analyzing intelligence information to assess developments, trends, and threat implications.\",\n",
      "\t\t\"Familiarity with machine learning and statistical methods applications to solve complex problem sets and achieve successful outcomes.\",\n",
      "\t\t\"Some experience querying, creating, and integrating data flows from an Elasticsearch instance to include building dashboards and presenting information via Kibana or Plotly Dash.\",\n",
      "\t\t\"Applied GIS work and familiarity with ESRI products and/or QGIS.\"\n",
      "\t],\n",
      "\t\"salary\": 160000.00\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9de14b44-a4e9-4f98-9120-41f24a83e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_output = output_parser.parse(text=response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "278be5c2-04f4-4711-bac6-261f4204430d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_title': 'Senior Geospatial Data Scientist',\n",
       " 'job_requirements': ['10+ years of experience working in US DoD and IC environments, preferably with CENTCOM or other COCOM elements.',\n",
       "  'Education in Geography, Data Science, Economics, Computer Science, etc.',\n",
       "  'Military and/or DoD/IC experience in any of the following disciplines: data science, computer vision, target development, geospatial, or statistical analysis.',\n",
       "  'Experience with spatial data and map based visualization tools along with data science fundamentals such as data engineering, coding in python, SQL, data structures and familiarity with Keras, Tensorflow, Neo4j, or PyTorch frameworks preferred.',\n",
       "  'Defining critical intelligence topics, initiating comprehensive research efforts, and analyzing intelligence information to assess developments, trends, and threat implications.',\n",
       "  'Familiarity with machine learning and statistical methods applications to solve complex problem sets and achieve successful outcomes.',\n",
       "  'Some experience querying, creating, and integrating data flows from an Elasticsearch instance to include building dashboards and presenting information via Kibana or Plotly Dash.',\n",
       "  'Applied GIS work and familiarity with ESRI products and/or QGIS.'],\n",
       " 'salary': 160000.0}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
