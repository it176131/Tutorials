{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdfbff51-4599-43ff-b312-03e228324ab2",
   "metadata": {},
   "source": [
    "The most important key building block in `LangChain` is the `chain`.\n",
    "A `chain` usually combines an LLM with a prompt, but also allows us to combine other chains and perform several operations on text.\n",
    "One of the powers of a `chain` is running it over many inputs at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbdda14-828e-488d-8505-2e8baeedb2ec",
   "metadata": {},
   "source": [
    "# `LLMChain`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1c030-a023-4b70-bcc1-788e9a7a3526",
   "metadata": {},
   "source": [
    "The `LLMChain` is a simple, but powerful chain that underpins a lot of the chains covered in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60b498c-e11a-4ec7-afbd-daf64250f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b82e217-ad3c-4374-a132-8ff05f388cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_version = \"2023-12-01-preview\"\n",
    "model = \"gpt-35-turbo-16k\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19e542-bfbc-4ec1-877d-7703a185d2f1",
   "metadata": {},
   "source": [
    "We initialize our model with a high temperature to elicit more randomness (\"creativity\") in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d117cc9-a06a-4257-840b-7cc0a995e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = AzureChatOpenAI(model=model, temperature=0.9, api_version=api_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d01146d-7391-4877-813c-8cbf6001e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template=\"What is the best name to describe a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b68cb-9ee5-4a92-9c28-b16ba91776f8",
   "metadata": {},
   "source": [
    "We combine the prompt and the model using the `LLMChain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda5adc0-44cf-4b22-896d-d348fd11c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(prompt=prompt, llm=chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59bd968-4462-477a-b9ec-56c048e637ee",
   "metadata": {},
   "source": [
    "We can run the chain by providing an input to the `run` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13a6f91d-c8d6-4a78-94c0-b95aec8b2bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RoyalRest'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffdcd40-32fd-4663-b0aa-9f72ba2a0aa0",
   "metadata": {},
   "source": [
    "# `SimpleSequentialChain`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05147575-d03a-4ca5-8687-77b6cb5693d8",
   "metadata": {},
   "source": [
    "The `LLMChain` is the most simple, basic type of chain in `LangChain`.\n",
    "The `SimpleSequentialChain` runs a sequence of chains one after another.\n",
    "This works well when we have chains that expect one input and return one output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164aeb27-802a-4ce7-aac8-a18e76e0b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a83d4c-bf7c-46a6-9a4a-604c47ad138a",
   "metadata": {},
   "source": [
    "To demonstrate, we'll treat our prior `LLMChain` as our first chain in a sequence of chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7198041b-7f59-4ce1-8ac9-9e98f1f2cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_one = chain.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fdecba-cf92-4ac8-b553-1f75bed7274b",
   "metadata": {},
   "source": [
    "Now we create a second chain to take the output of the first chain (`chain_one`), a company name, and pass it into a second chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b32aaf-1154-4566-a80c-5d743109cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    template=\"Write a 20 word description for the following company: {company_name}\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(prompt=second_prompt, llm=chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c8ea8-f766-4a1e-b72c-0786bcf29b59",
   "metadata": {},
   "source": [
    "We supply both chains to `SimpleSequentialChain` in the order we want to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63c9da46-a554-467f-bb68-1546125b73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da2207-aed3-4210-b11c-93055e7100fc",
   "metadata": {},
   "source": [
    "We run the `simple_chain` like any other chain using the `run` method.\n",
    "Remember that we are inputting a product as that is what the first chain (`chain_one`) expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "945c116b-7b8c-4646-a130-45d4822f0918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LLMChain' object has no attribute 'callbacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msimple_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\base.py:511\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    510\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    512\u001b[0m         _output_key\n\u001b[0;32m    513\u001b[0m     ]\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    517\u001b[0m         _output_key\n\u001b[0;32m    518\u001b[0m     ]\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\base.py:316\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    315\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    317\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    318\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    319\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    320\u001b[0m )\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    303\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    304\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    305\u001b[0m     inputs,\n\u001b[0;32m    306\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    307\u001b[0m )\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 310\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    313\u001b[0m     )\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    315\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\sequential.py:180\u001b[0m, in \u001b[0;36mSimpleSequentialChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    178\u001b[0m color_mapping \u001b[38;5;241m=\u001b[39m get_color_mapping([\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchains))])\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, chain \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchains):\n\u001b[1;32m--> 180\u001b[0m     _input \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstep_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip_outputs:\n\u001b[0;32m    182\u001b[0m         _input \u001b[38;5;241m=\u001b[39m _input\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\base.py:511\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    510\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    512\u001b[0m         _output_key\n\u001b[0;32m    513\u001b[0m     ]\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    517\u001b[0m         _output_key\n\u001b[0;32m    518\u001b[0m     ]\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\base.py:295\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    292\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_inputs(inputs)\n\u001b[0;32m    293\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m CallbackManager\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[0;32m    294\u001b[0m     callbacks,\n\u001b[1;32m--> 295\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m,\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    297\u001b[0m     tags,\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags,\n\u001b[0;32m    299\u001b[0m     metadata,\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    303\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    304\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    305\u001b[0m     inputs,\n\u001b[0;32m    306\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    307\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LLMChain' object has no attribute 'callbacks'"
     ]
    }
   ],
   "source": [
    "simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11227a7c-16d6-41cb-b063-147e11760f78",
   "metadata": {},
   "source": [
    "Nearly 200 versions of `LangChain` have come out since the the DeepLearningAI tutorial was created.\n",
    "After some toying I found that I needed to supply `output_key=\"company_name\"` to `chain_one`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f432eab8-8079-42de-aeee-7b838b844196",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_one = LLMChain(prompt=prompt, llm=chat, output_key=\"company_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf159ad-31be-4971-b371-e4e2b65b6504",
   "metadata": {},
   "source": [
    "This doesn't affect the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42dbadc0-8078-49b8-a67c-2f70c641ef3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Royalty Linens\" or \"Regal Comforts\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_one.run(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2710007b-3d61-4125-9487-88f181577f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mRoyalRest Beddings\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mRoyalRest Beddings is a luxury bedding company that offers premium mattresses, pillows, and linens for a comfortable and rejuvenating sleep experience.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'RoyalRest Beddings is a luxury bedding company that offers premium mattresses, pillows, and linens for a comfortable and rejuvenating sleep experience.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)\n",
    "simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa9bc5-6458-4211-88ad-da29fb5070d1",
   "metadata": {},
   "source": [
    "# `SequentialChain`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd9b206-f26c-474f-99fe-098e062e3300",
   "metadata": {},
   "source": [
    "The `SimpleSequentialChain` works well when there is a single input and single output.\n",
    "To supply more than one input or return more than one output we use the `SequentialChain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23105dad-bdef-4dbc-935f-d88062c7483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a4f99-d8a9-4c57-a03f-f23548956e5e",
   "metadata": {},
   "source": [
    "We generate an intial chain to translate a review into English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdf1ab0d-00d0-4743-adec-158ad32768ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_one = ChatPromptTemplate.from_template(\n",
    "    template=\"Translate the following review to english:\\n\\n{review}\"\n",
    ")\n",
    "chain_one = LLMChain(prompt=prompt_one, llm=chat, output_key=\"english_review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50c442-2a40-466d-be63-00c8d71160a1",
   "metadata": {},
   "source": [
    "We generate a second chain that summarizes the output of `chain_one`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "194e2566-4287-4a80-bc91-e00a081b62ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_two = ChatPromptTemplate.from_template(\n",
    "    template=\"Can you summarize the following reveiw in 1 sentence:\\n\\n{english_review}\"\n",
    ")\n",
    "chain_two = LLMChain(prompt=prompt_two, llm=chat, output_key=\"summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296818db-3c0c-4d40-b0f1-d515f5ee3001",
   "metadata": {},
   "source": [
    "We generate a third chain that determines what language the original review is in, using the same input as `chain_one`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8f1c726-4c6f-4119-a16c-c8cb31ebe53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_three = ChatPromptTemplate.from_template(\n",
    "    template=\"What language is the following review:\\n\\n{review}\"\n",
    ")\n",
    "chain_three = LLMChain(prompt=prompt_three, llm=chat, output_key=\"language\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d943d-787a-45e2-8589-c882873e5734",
   "metadata": {},
   "source": [
    "We generate a fourth chain that responds to the summary produced by `chain_two` in the language produced by `chain_three`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94cafe31-b696-4444-98fe-47bf1b5f6e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_four = ChatPromptTemplate.from_template(\n",
    "    template=\"\"\"Write a follow up response to the following summary in the specified language:\n",
    "    \n",
    "    Summary: {summary}\n",
    "    \n",
    "    Language: {language}\"\"\"\n",
    ")\n",
    "chain_four = LLMChain(prompt=prompt_four, llm=chat, output_key=\"followup_message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fd28a-d15b-4d6c-95d2-98e97be7ffaa",
   "metadata": {},
   "source": [
    "Finally, we generate a final chain that combines `chain_one`, `chain_two`, `chain_three`, and `chain_four`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c37ee81-08b3-422f-9956-4b3c6e525479",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"review\"],\n",
    "    output_variables=[\"english_review\", \"summary\", \"followup_message\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2aa2e15-4c93-4fb8-a2bb-5f0a1d751501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review': \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\",\n",
       " 'english_review': \"I find the taste mediocre. The foam doesn't hold, it's weird. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\",\n",
       " 'summary': 'The reviewer expresses disappointment with the mediocre taste of the product, highlighting issues with the foam not holding, implying a possible difference in quality compared to the same product purchased in stores.',\n",
       " 'followup_message': \"Cher critique,\\n\\nNous vous remercions d'avoir partagé votre avis concernant notre produit. Nous sommes sincèrement désolés d'apprendre que vous avez été déçu par son goût moyen ainsi que par les problèmes rencontrés avec la tenue de la mousse. Nous accordons une grande importance à la qualité de nos produits et nous sommes soucieux de satisfaire nos clients.\\n\\nNous souhaiterions avoir plus de détails sur les problèmes que vous avez rencontrés avec la mousse afin de mieux comprendre la situation. Veuillez nous indiquer si vous avez suivi les instructions d'utilisation correctement. Il est possible que des erreurs dans la préparation ou l'utilisation aient affecté le résultat final.\\n\\nConcernant la différence de qualité que vous avez perçue par rapport à notre produit acheté en magasin, nous tenons à vous assurer que nos produits sont fabriqués selon les mêmes normes de qualité, que ce soit pour les ventes en ligne ou en magasin. Néanmoins, il est possible que des variables d'utilisation, de transport ou de stockage aient influencé les performances du produit.\\n\\nNous aimerions avoir l'opportunité de rectifier cette situation. Pourriez-vous s'il vous plaît nous contacter directement avec plus de détails sur votre expérience, ainsi que toutes les informations relatives à votre achat (lieu, date, référence du produit) ? Nous serions ravis de pouvoir vous offrir une solution appropriée afin de regagner votre confiance.\\n\\nVotre satisfaction est notre priorité absolue et nous espérons avoir la possibilité de regagner votre estime.\\n\\nCordialement,\\nVotre équipe dévouée\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\"\n",
    "final_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd43661d-9810-4975-92cd-728003d274f5",
   "metadata": {},
   "source": [
    "It's important to note that the `input_keys` and `output_keys` need to be precise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9aac80-51e2-4638-847f-7b8605b196c0",
   "metadata": {},
   "source": [
    "# `LLMRouterChain`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d808ee5-1819-4013-9430-c336136f858f",
   "metadata": {},
   "source": [
    "The `LLMRouterChain` allows us to route inputs to a chain, respective of the input.\n",
    "For example, we can have multiple sub-chains, each specialized for a specific input, handled via routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e85629c4-897b-43ab-98cf-5e0c887d9ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f503d35-d819-47d0-8303-baca00104055",
   "metadata": {},
   "source": [
    "Suppose we are routing inputs on four different subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80d3e39e-20e0-4831-82b3-f5a38a2bc52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor.\n",
    "You are great at answering questions about physics in a concise\n",
    "and easy to understand manner.\n",
    "When you don't know the answer to a question you admit\n",
    "that you don't know.\n",
    "\n",
    "Here is a queston:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf45e81f-9072-40ad-9c72-6c0adcba634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_template = \"\"\"You are a very good mathematician.\n",
    "You are great at answering math questions.\n",
    "You are so good because you are able to break down\n",
    "hard problems into their component parts,\n",
    "answer the component parts, and then put them together\n",
    "to answer the broader question.\n",
    "\n",
    "Here is the question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8efcc24-aa74-4270-aec8-689782fde494",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_template = \"\"\"You are a very good historian.\n",
    "You have an excellent knowledge of and understanding of people,\n",
    "events and contexts from a range of historical periods.\n",
    "You have the ability to think, reflect, debate, discuss and\n",
    "evaluate the past. You have a resepect for historical evidence\n",
    "and the ability to make use of it to support your explanations\n",
    "and judgments.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42e7a0ff-ccf5-42ec-9ee6-31fa5dac2c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "computer_science_template = \"\"\"You are a successful computer scientist.\n",
    "You have a passion for creativity, collaboration,\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\n",
    "understanding of theories and algorithms, and excellent communication\n",
    "skills. You are great at answering coding questions.\n",
    "You are so good because you know how to solve a problem by\n",
    "describing the solution in imperative steps\n",
    "that a machine can easily interpret and you know how to\n",
    "choose a solution that has a good balance between\n",
    "time complexity and space complexity.\n",
    "\n",
    "Here is the question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057c1a62-6da3-471e-b61b-16777c055c87",
   "metadata": {},
   "source": [
    "We can add more information about our prompts which we will pass to a `MultiPromptChain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69864b2e-0e85-4597-943e-118936fdd0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\",\n",
    "        \"description\": \"Good for answering questions about physics\",\n",
    "        \"prompt_template\": physics_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"Good for answering questions about math\",\n",
    "        \"prompt_template\": math_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"history\",\n",
    "        \"description\": \"Good for answering questions about history\",\n",
    "        \"prompt_template\": history_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer_science\",\n",
    "        \"description\": \"Good for answering questions about computer science\",\n",
    "        \"prompt_template\": computer_science_template,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05b73457-4dcd-4df1-bd29-790b617b6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowering temperature to reduce randomness.\n",
    "chat = AzureChatOpenAI(model=model, temperature=0, api_version=api_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6df333bf-4206-4462-8346-c52aa359336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=template)\n",
    "    chain = LLMChain(prompt=prompt, llm=chat)\n",
    "    destination_chains[name] = chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed8fcd-0b6d-4c84-ad66-90f86ee8ec5b",
   "metadata": {},
   "source": [
    "Each `chain` in `destination_chains` will be called by the `LLMRouterChain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbcf2177-8341-4637-9cbd-2a852d66db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fb10b-34b2-4ce2-bb4a-c454c0576a38",
   "metadata": {},
   "source": [
    "In addition to the `destination_chains`, we need a default chain that will be called when the `LLMRouterChain` can't decided which sub-chain to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec0f1467-be35-43e8-85a7-681c733d64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(template=\"{input}\")\n",
    "default_chain = LLMChain(prompt=default_prompt, llm=chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7680e2-d819-4e0c-9eba-595221dfb988",
   "metadata": {},
   "source": [
    "We define a prompt to instruct the model on how to route between the different chains.\n",
    "There are also general instructions for what needs to be done, as well as what the output format should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b58c270-9386-4892-9fd2-2cbcb9da732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_prompt = \"\"\"Given a raw text input to a\n",
    "langauge model, select the model prompt best suited for the input.\n",
    "You will be given the names of the available prompts and a\n",
    "description of what the prompt is best suited for.\n",
    "You may also revise the original input if you think that revising\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json) >>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b276d7-222c-4295-9044-9127d65242e6",
   "metadata": {},
   "source": [
    "To put it all together, we first format the `multi_prompt` with the `destinations_str`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "439bd652-69af-4ca0-8271-8f8e2c073c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = multi_prompt.format(destinations=destinations_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e3b99-3f86-4ecc-a2d4-1a0412789ff9",
   "metadata": {},
   "source": [
    "We create the prompt using `PromptTemplate`.\n",
    "We use `PromptTemplate` because it provides more paramters than the `ChatPromptTemplate` we've been using.\n",
    "Note that the `RouterOutputParser` is important as it will help the chain decided which subchain to route between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1eb14a46-a087-477e-88f5-d9245a878988",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf4cab-6204-4bce-9750-d19d91136233",
   "metadata": {},
   "source": [
    "We combine the `router_prompt` with the model into a `LLMRouterChain` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acf458cd-ec73-45c3-8a6d-de6b59e44877",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain = LLMRouterChain.from_llm(llm=chat, prompt=router_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d52306-8e15-4bbb-8bd3-6961796275ea",
   "metadata": {},
   "source": [
    "Finally, we put it all together to create the final chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a96d90e7-2f60-49a9-9e66-b5be0e78a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85b4619e-2f19-47aa-afc5-f866ed20e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A2644752\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Black body radiation refers to the electromagnetic radiation emitted by an object that absorbs all incident radiation and reflects or transmits none. It is called \"black body\" because it is an idealized object that absorbs all radiation without any reflection or transmission. \\n\\nAccording to Planck\\'s law, the intensity and spectrum of black body radiation depend solely on the temperature of the object. As the temperature increases, the peak wavelength of the radiation shifts towards shorter wavelengths, resulting in a change in color. For example, a black body at room temperature emits mostly infrared radiation, while a hotter black body, like a red-hot iron, emits visible light.\\n\\nThe concept of black body radiation played a crucial role in the development of quantum mechanics. Max Planck introduced the idea of quantization to explain the observed spectrum of black body radiation, which led to the birth of quantum theory. Albert Einstein further expanded on this concept with his explanation of the photoelectric effect, which earned him the Nobel Prize in Physics.\\n\\nIn summary, black body radiation refers to the electromagnetic radiation emitted by an object that absorbs all incident radiation. Its properties are determined solely by the temperature of the object, and it played a significant role in the development of quantum mechanics.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5f23399-a955-4aaa-9f81-b9a175437e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A2644752\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math: {'input': 'What is the area under the function y=x^2 from -1 to +1?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Thank you for your kind words! I'll be happy to help you with your question.\\n\\nTo find the area under the function y = x^2 from -1 to +1, we need to calculate the definite integral of the function over that interval.\\n\\nThe definite integral of a function represents the signed area between the function and the x-axis over a given interval. In this case, we want to find the area between the curve y = x^2 and the x-axis from x = -1 to x = 1.\\n\\nTo solve this, we can use the definite integral formula:\\n\\n∫[a to b] f(x) dx\\n\\nIn our case, a = -1 and b = 1, and f(x) = x^2. So, the integral becomes:\\n\\n∫[-1 to 1] x^2 dx\\n\\nTo evaluate this integral, we can use the power rule for integration. According to the power rule, the integral of x^n with respect to x is (x^(n+1))/(n+1), where n is any real number except -1.\\n\\nApplying the power rule to our integral, we get:\\n\\n∫[-1 to 1] x^2 dx = [(x^3)/3] evaluated from -1 to 1\\n\\nEvaluating the integral at the limits, we have:\\n\\n[(1^3)/3] - [(-1^3)/3] = (1/3) - (-1/3) = 2/3\\n\\nTherefore, the area under the function y = x^2 from -1 to +1 is 2/3 square units.\\n\\nI hope this helps! Let me know if you have any further questions.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.run(\"What is the area under the function y=x^2 from -1 to +1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1a13751-b8d6-4288-967f-76ca39d793be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A2644752\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biology: {'input': 'Why does every cell in our body contain DNA?'}"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received invalid destination chain name 'biology'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfinal_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhy does every cell in our body contain DNA?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\base.py:511\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    510\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    512\u001b[0m         _output_key\n\u001b[0;32m    513\u001b[0m     ]\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    517\u001b[0m         _output_key\n\u001b[0;32m    518\u001b[0m     ]\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\base.py:316\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    315\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    317\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    318\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    319\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    320\u001b[0m )\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    303\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    304\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    305\u001b[0m     inputs,\n\u001b[0;32m    306\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    307\u001b[0m )\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 310\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    313\u001b[0m     )\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    315\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\Sandbox\\PRIVATE-RAI\\env\\Lib\\site-packages\\langchain\\chains\\router\\base.py:106\u001b[0m, in \u001b[0;36mMultiRouteChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_chain(route\u001b[38;5;241m.\u001b[39mnext_inputs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived invalid destination chain name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroute\u001b[38;5;241m.\u001b[39mdestination\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Received invalid destination chain name 'biology'"
     ]
    }
   ],
   "source": [
    "final_chain.run(\"Why does every cell in our body contain DNA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552f131-0300-44be-83c9-42e31dfda64b",
   "metadata": {},
   "source": [
    "The last example failed, but I was impressed by the math example!\n",
    "Rather than using prompt engineering to handle situations like this, I'd use `Pydantic` and some kind of retry method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
